{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#API_KEY = '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'\n",
        "!pip install openai\n"
      ],
      "metadata": {
        "id": "Gi7QBOouEM45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4759bb55-0f8d-41a4-aa9c-3a648ef34218"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m204.8/226.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1ddeAYPHbPS",
        "outputId": "630bddbe-a0a2-4cee-a1a7-98e81a4485d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.23.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (0.26.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1->replicate) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>1->replicate) (2.16.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: replicate\n",
            "Successfully installed replicate-0.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "import requests"
      ],
      "metadata": {
        "id": "n0MZzHQcHbx2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r8_1OmmyccX5HgyAoFp7zYrzZZM50Rvbm34dyeiM    # REPLICATE FOCUSS API\n",
        "# get a token: https://replicate.com/account\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11tuLo-SHeLe",
        "outputId": "479a3644-9436-4072-cbbe-da078b892c8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n",
        "\n"
      ],
      "metadata": {
        "id": "J_cyuLapM5UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ebe083-aaa9-4cf4-d6ba-01600a49907b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing_extensions --upgrade\n"
      ],
      "metadata": {
        "id": "TP_-auEZPHt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4b5e37-4b51-418d-87fb-f01cf5cc3f44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --upgrade\n"
      ],
      "metadata": {
        "id": "djW78oRRPOqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c85c21e-6ad5-46be-bc98-ba69264795ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "id": "KlpuKVkNXAY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e857c67-e73c-497f-b17f-bb02b2c438d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratelimit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oza0ad5Pa5kM",
        "outputId": "47a8b0a8-ab20-4121-defd-94f05aab3e4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ratelimit\n",
            "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ratelimit\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5894 sha256=3ad4e79b69ce27ec38cb5bb856a2cbf19218b2d6683ea787611eed9daaf35440\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/5f/ba/e972a56dcbf5de9f2b7d2b2a710113970bd173c4dcd3d2c902\n",
            "Successfully built ratelimit\n",
            "Installing collected packages: ratelimit\n",
            "Successfully installed ratelimit-2.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtt-zbSFfYms",
        "outputId": "cb294e77-a4ac-4355-ed08-d2480692a3ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#..........IMAGES..................\n",
        "\n",
        "from openai import OpenAI\n",
        "import base64\n",
        "import os\n",
        "\n",
        "apikey = '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'\n",
        "\n",
        "client = OpenAI(api_key=apikey)\n",
        "\n",
        "def create_from_data(data):\n",
        "\n",
        "  if not os.path.exists(\"images\"):\n",
        "    os.makedirs(\"images\")\n",
        "\n",
        "  image_number = 0\n",
        "  for element in data:\n",
        "    if element[\"type\"] != \"image\":\n",
        "      continue\n",
        "    print(element[\"description\"])\n",
        "    image_number +=1\n",
        "    image_name = f\"image_{image_number}.webp\"\n",
        "    generate(element[\"description\"],os.path.join(\"images\",image_name))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate(prompt,output_file,size=\"1024x1024\"):\n",
        " output = replicate.run(\n",
        "    \"konieshadow/fooocus-api:fda927242b1db6affa1ece4f54c37f19b964666bf23b0d06ae2439067cd344a4\",\n",
        "    input={\n",
        "        \"prompt\": prompt,\n",
        "        \"cn_type1\": \"ImagePrompt\",\n",
        "        \"cn_type2\": \"ImagePrompt\",\n",
        "        \"cn_type3\": \"ImagePrompt\",\n",
        "        \"cn_type4\": \"ImagePrompt\",\n",
        "        \"sharpness\": 2,\n",
        "        \"image_seed\": 50403806253646856,\n",
        "        \"uov_method\": \"Disabled\",\n",
        "        \"image_number\": 1,\n",
        "        \"guidance_scale\": 4,\n",
        "        \"refiner_switch\": 0.5,\n",
        "        \"negative_prompt\": \"\",\n",
        "        \"style_selections\": \"Fooocus V2,Fooocus Enhance,Fooocus Sharp\",\n",
        "        \"uov_upscale_value\": 0,\n",
        "        \"outpaint_selections\": \"\",\n",
        "        \"outpaint_distance_top\": 0,\n",
        "        \"performance_selection\": \"Speed\",\n",
        "        \"outpaint_distance_left\": 0,\n",
        "        \"aspect_ratios_selection\": \"704*1408\",\n",
        "        \"outpaint_distance_right\": 0,\n",
        "        \"outpaint_distance_bottom\": 0,\n",
        "        \"inpaint_additional_prompt\": \"\"\n",
        "    }\n",
        " )\n",
        "\n",
        "\n",
        "  # Extracting the URL from the output list\n",
        " if output:  # Check if output list is not empty\n",
        "      image_url = output[0]  # Access the first element of the list\n",
        "      print(\"URL:\", image_url)\n",
        " else:\n",
        "      print(\"Output list is empty.\")\n",
        "\n",
        "\n",
        "  # # Download the image\n",
        " response = requests.get(image_url)\n",
        "\n",
        "  # # Save the image in .webp format\n",
        " with open(output_file, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        " print(\"Image saved as 'generated_image.webp'\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UFyI2PflsyLt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#.............NARRATION..................................\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#.......................................................\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from gtts import gTTS\n",
        "import requests\n",
        "\n",
        "narration_api = \"openai\" #(or openai)\n",
        "\n",
        "def parse(narration):\n",
        "  output = []\n",
        "  lines = narration.split(\"\\n\")\n",
        "  for line in lines:\n",
        "    if line.startswith('Narrator: \"'):\n",
        "      text = line.replace('Narrator: \"', '')\n",
        "      output.append({\n",
        "          \"type\":\"text\",\n",
        "          \"content\":text,\n",
        "      })\n",
        "\n",
        "    elif line.startswith('['):\n",
        "      background = line.strip('[]')\n",
        "      output.append({\n",
        "          \"type\":\"image\",\n",
        "          \"description\":background,\n",
        "      }\n",
        "      )\n",
        "\n",
        "  return output\n",
        "\n",
        "def create(data,output_folder):\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "      os.makedirs(output_folder)\n",
        "\n",
        "    n=0\n",
        "    for element in data:\n",
        "      if element[\"type\"]!= \"text\":\n",
        "        continue\n",
        "      n+=1\n",
        "      output_file = os.path.join(output_folder,f\"narration_{n}.mp3\")\n",
        "\n",
        "\n",
        "      # print(element[\"content\"]) # ......for GTTS\n",
        "      # language = 'en'\n",
        "      # tts = gTTS(text=element[\"content\"], lang=language, slow=False)\n",
        "      # tts.save(output_file)\n",
        "\n",
        "\n",
        "      #...............................................................\n",
        "      url = \"https://cloudlabs-text-to-speech.p.rapidapi.com/synthesize\"\n",
        "\n",
        "      payload = {\n",
        "        \"voice_code\": \"en-US-1\",\n",
        "        \"text\": element[\"content\"],\n",
        "        \"speed\": \"1.00\",\n",
        "        \"pitch\": \"1.00\",\n",
        "        \"output_type\": \"audio_url\"\n",
        "      }\n",
        "      headers = {\n",
        "        \"content-type\": \"application/x-www-form-urlencoded\",\n",
        "        \"X-RapidAPI-Key\": \"b4ae981829mshdad18686bc052fap1f5aacjsn9af0875c5543\",\n",
        "        \"X-RapidAPI-Host\": \"cloudlabs-text-to-speech.p.rapidapi.com\"\n",
        "      }\n",
        "\n",
        "      response = requests.post(url, data=payload, headers=headers)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "        response_json = response.json()\n",
        "        print(response_json)  # Print the response JSON to inspect its structure\n",
        "\n",
        "        # Extract the audio URL from the 'result' key in the response JSON\n",
        "        result = response_json.get('result')\n",
        "        if result:\n",
        "            audio_url = result.get('audio_url')\n",
        "\n",
        "            if audio_url:\n",
        "                # Fetch the audio content from the URL\n",
        "                audio_response = requests.get(audio_url, stream=True)\n",
        "\n",
        "                # Save the audio content to an MP3 file\n",
        "                with open(output_file, \"wb\") as f:\n",
        "                    for chunk in audio_response.iter_content(chunk_size=1024):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                print(\"Audio file saved successfully.\")\n",
        "            else:\n",
        "                print(\"Failed to get audio URL from the response.\")\n",
        "        else:\n",
        "            print(\"Failed to get 'result' key from the response.\")\n",
        "      else:\n",
        "          print(\"Failed to make the API request. Status code:\", response.status_code)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tyG8p93uW7ET"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A6Dlp8MtjOTY"
      },
      "outputs": [],
      "source": [
        "#.........SCRIPT......................................\n",
        "\n",
        "import json\n",
        "# import images\n",
        "# import narration\n",
        "\n",
        "apikey = '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'\n",
        "\n",
        "client = OpenAI(api_key=apikey)\n",
        "#client = OpenAI()\n",
        "with open(\"source_material.txt\") as f:\n",
        "  source_material = f.read()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages =[\n",
        "        {\n",
        "\n",
        "         \"role\": \"system\",\n",
        "         \"content\":\"\"\"You are a Youtube short narration generator. You generate\n",
        "         a total of 30 seconds of a narration. Make sure that each narration is less than 12 words and not more that 5 seconds. The shorts you create have a\n",
        "         background that fades from image to image as the image is going on.\n",
        "\n",
        "         Respond in the following format:\n",
        "         ###\n",
        "\n",
        "         [Description of the background image]\n",
        "\n",
        "         Narrator: \"A few sentences of narration\"\n",
        "\n",
        "         [Description of the background image]\n",
        "\n",
        "         Narrator: \"A few sentences of narration\"\n",
        "\n",
        "         [Description of the background image]\n",
        "\n",
        "         Narrator: \"A few sentences of narration\"\n",
        "\n",
        "         [Description of the background image]\n",
        "\n",
        "         Narrator: \"A few sentences of narration\"\n",
        "\n",
        "         [Description of the background image]\n",
        "\n",
        "         Narrator: \"A few sentences of narration\"\n",
        "\n",
        "         [Description of the background image]\n",
        "\n",
        "         Narrator: \"A few sentences of narration\"\n",
        "\n",
        "         ###\n",
        "\n",
        "        You should add a description of a fitting background image in between all of the\n",
        "        narrations. It will later be used to generate an image with AI\n",
        "        \"\"\"\n",
        "         },\n",
        "\n",
        "         {\n",
        "            \"role\":\"user\",\n",
        "            \"content\": f\"Create a YouTube short narration based on the following source material:\\n\\n{source_material}\"\n",
        "\n",
        "         }\n",
        "\n",
        "              ]\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response_text = response.choices[0].message.content\n",
        "print(\"GPT Answer: \",response_text )\n",
        "with open(\"response.txt\",\"w\") as f:\n",
        "  f.write(response_text)\n",
        "data = parse(response_text)\n",
        "\n",
        "with open(\"data.json\",\"w\") as f:\n",
        "  json.dump(data,f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQUjyqWmZTkd",
        "outputId": "bd0943f9-1526-4e9c-f5b9-1da0985acf81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT Answer:  ### \n",
            "\n",
            "[Image fades from images of war-torn cities to a map of the globe with arrows pointing in different directions]\n",
            "\n",
            "Narrator: \"World War II, involving 50+ nations, fighting on land, sea, and air.\"\n",
            "\n",
            "[Image fades from a concentration camp to a photo of Adolf Hitler]\n",
            "\n",
            "Narrator: \"Hitler's rise to power, leading to the Holocaust and the 'Final Solution'.\"\n",
            "\n",
            "[Image fades from a bombed city to soldiers on the battlefield]\n",
            "\n",
            "Narrator: \"Allies' victories in Europe and the Pacific lead to Japan's surrender.\"\n",
            "\n",
            "[Image fades from world leaders at a conference to a mushroom cloud]\n",
            "\n",
            "Narrator: \"The devastating war ends with the atomic bombing of Hiroshima and Nagasaki.\"\n",
            "\n",
            "[Image fades from a victorious soldier to a United Nations flag]\n",
            "\n",
            "Narrator: \"United Nations created as a peacekeeping force after the deadly conflict.\"\n",
            "\n",
            "###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = \"narrations\"\n",
        "create(data,output_folder)\n",
        "#exit()\n"
      ],
      "metadata": {
        "id": "beKBexdRI-by",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d6f74c-c3c7-4b47-f73c-32229e7b1ceb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to make the API request. Status code: 429\n",
            "Failed to make the API request. Status code: 429\n",
            "Failed to make the API request. Status code: 429\n",
            "Failed to make the API request. Status code: 429\n",
            "Failed to make the API request. Status code: 429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_from_data(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "x9O2bX2STAox",
        "outputId": "af7b824e-2171-49a3-9339-fd12755bc619"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image fades from images of war-torn cities to a map of the globe with arrows pointing in different directions\n",
            "URL: https://replicate.delivery/pbxt/SVGGchAXCrIbEZ35KclpHR9TRK9062E8FUuVQ8Mep63Xz7LJA/b87894bb-bf5e-4c5e-9e56-c670ccecbe52.png\n",
            "Image saved as 'generated_image.webp'\n",
            "Image fades from a concentration camp to a photo of Adolf Hitler\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4b0aa1d982dd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-c8781f8e6173>\u001b[0m in \u001b[0;36mcreate_from_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimage_number\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"image_{image_number}.webp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c8781f8e6173>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(prompt, output_file, size)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1024x1024\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m  output = replicate.run(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;34m\"konieshadow/fooocus-api:fda927242b1db6affa1ece4f54c37f19b964666bf23b0d06ae2439067cd344a4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     input={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/client.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, ref, input, **params)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     async def async_run(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(client, ref, input, **params)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/replicate/prediction.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"succeeded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"failed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"canceled\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .....................TRANSCRIPTION.......................\n",
        "from pydub import AudioSegment\n",
        "\n",
        "import json\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "offset = 500\n",
        "\n",
        "\n",
        "def get_audio_duration(audio_file):\n",
        "  return len(AudioSegment.from_file(audio_file))\n",
        "\n",
        "def get_narrations() -> str:\n",
        "  with open(\"data.json\") as f:\n",
        "    narration_data = json.load(f)\n",
        "  narrations = []\n",
        "\n",
        "  for element in narration_data:\n",
        "    if element[\"type\"] == \"text\":\n",
        "      narrations.append(element)\n",
        "\n",
        "  return narrations\n",
        "\n",
        "def write_text(text, frame, video_writer):\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "  white_colour = (255, 255, 255)\n",
        "  black_colour =(0, 0, 0)\n",
        "  thickness = 10\n",
        "  font_scale = 3\n",
        "  border = 5\n",
        "\n",
        "  # Positing text at centered position\n",
        "\n",
        "  text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
        "  text_x = (frame.shape[1] - text_size[0]) //2 # horizontal centre\n",
        "  text_y = (frame.shape[0] - text_size[1]) //2 # vertical centre\n",
        "  org = (text_x, text_y) # Position of the text\n",
        "\n",
        "  #Open the video file\n",
        "\n",
        "  frame = cv2.putText(frame, text, org, font, font_scale, black_colour, thickness+border*2, cv2.LINE_AA)\n",
        "  frame = cv2.putText(frame, text, org, font, font_scale, white_colour, thickness, cv2.LINE_AA)\n",
        "\n",
        "  video_writer.write(frame)\n",
        "\n",
        "def add_narration_to_video(input_video, output_video):\n",
        "  #Open the videofile\n",
        "\n",
        "  cap = cv2.VideoCapture(input_video)\n",
        "\n",
        "  #Define the codec and create a VideoWriter object to save the output video\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "  temp_video = \"with_transcript.mp4\"\n",
        "  out = cv2.VideoWriter(temp_video, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "  full_narration = AudioSegment.empty()\n",
        "  narrations = get_narrations()\n",
        "\n",
        "  for a, narration in enumerate(narrations):\n",
        "    audio = os.path.join(\"narrations\",f\"narration_{a+1}.mp3\")\n",
        "    duration = get_audio_duration(audio)\n",
        "    narration_frames = math.floor(duration/1000*30)\n",
        "\n",
        "    full_narration += AudioSegment.from_file(audio)\n",
        "\n",
        "    char_count = len(narration[\"content\"].replace(\" \",\"\"))\n",
        "    ms_per_char = duration/char_count\n",
        "\n",
        "    frames_written = 0\n",
        "    words = narration[\"content\"].split(\" \")\n",
        "\n",
        "    for w, word in enumerate(words):\n",
        "      word_ms = len(word)*ms_per_char\n",
        "\n",
        "      if a==0 and w==0:\n",
        "        word_ms -= offset\n",
        "        if word_ms < 0:\n",
        "          word_ms = 0\n",
        "\n",
        "      for b in range(math.floor(word_ms/1000*30)):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "          break\n",
        "        write_text(word, frame, out)\n",
        "        frames_written += 1\n",
        "\n",
        "    for a in range(narration_frames - frames_written):\n",
        "      out.write(frame)\n",
        "\n",
        "  temp_narration = \"narration.mp3\"\n",
        "  full_narration.export(temp_narration, format=\"mp3\")\n",
        "\n",
        "\n",
        "\n",
        "  #Release the VideoCapture and VideoWriter objects\n",
        "\n",
        "  cap.release()\n",
        "  out.release()\n",
        "\n",
        "\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "  ffmpeg_command = [\n",
        "      'ffmpeg',\n",
        "      '-i', temp_video,\n",
        "      '-i', temp_narration,\n",
        "      '-map', '0:v',\n",
        "      '-map', '1:a',\n",
        "      '-c:v', 'copy',\n",
        "      '-c:a', 'aac',  # Changed codec to aac\n",
        "      '-strict', 'experimental',\n",
        "      '-shortest',\n",
        "      output_video\n",
        "  ]\n",
        "\n",
        "\n",
        "  subprocess.run(ffmpeg_command)\n",
        "  os.remove(temp_video)\n",
        "  os.remove(temp_narration)\n"
      ],
      "metadata": {
        "id": "XWNzuQ2Sg6QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#.............VIDEO...................."
      ],
      "metadata": {
        "id": "twMUpeeD-fVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "def get_audio_duration(audio_file):\n",
        "  audio = AudioSegment.from_file(audio_file)\n",
        "  return len(audio)\n",
        "\n",
        "def resize_image(image, width, height):\n",
        "  aspect_ratio = image.shape[1]/image.shape[0]\n",
        "\n",
        "  if aspect_ratio > (width/ height):\n",
        "    new_width = width\n",
        "    new_height = int(width/aspect_ratio)\n",
        "  else:\n",
        "    new_height = height\n",
        "    new_width = int(height * aspect_ratio)\n",
        "\n",
        "  return cv2.resize(image, (new_width, new_height))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "width, height = 704,1408\n",
        "frame_rate = 30\n",
        "fade_time = 1000\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_file = 'vertical_video.mp4'\n",
        "out = cv2.VideoWriter(output_file, fourcc, frame_rate, (width, height))\n",
        "\n",
        "image_paths = sorted(os.listdir(\"images\"))  # Sort the image paths for consistent order\n",
        "\n",
        "print (image_paths)\n",
        "\n",
        "for i, image in enumerate(image_paths):\n",
        "\n",
        "    image1 = cv2.imread(os.path.join(\"images\", image_paths[i]))\n",
        "\n",
        "    if i<len(image_paths)-1:\n",
        "     image2 = cv2.imread(os.path.join(\"images\", image_paths[i + 1]))\n",
        "    else:\n",
        "     image2 = cv2.imread(os.path.join(\"images\", image_paths[0]))\n",
        "\n",
        "\n",
        "    # image1 = resize_image(image1, 1080, 1920)\n",
        "    # image2 = resize_image(image2, 1080, 1920)\n",
        "\n",
        "\n",
        "    narration = os.path.join(\"narrations\",f\"narration_{i+1}.mp3\")\n",
        "    duration = get_audio_duration(narration)\n",
        "\n",
        "    if i>0:\n",
        "     duration -= fade_time\n",
        "\n",
        "    if i == len(image_paths)-1:\n",
        "     duration -= fade_time\n",
        "\n",
        "\n",
        "    for j in range(math.ceil(duration / 1000 * frame_rate)):\n",
        "        vertical_video_frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        vertical_video_frame[:image1.shape[0], :] = image1\n",
        "        out.write(vertical_video_frame)\n",
        "\n",
        "    for alpha in np.linspace(0, 1, math.ceil(fade_time / 1000 * frame_rate)):\n",
        "        blended_image = cv2.addWeighted(image1, 1 - alpha, image2, alpha, 0)\n",
        "        vertical_video_frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        vertical_video_frame[:image1.shape[0], :] = blended_image\n",
        "        out.write(vertical_video_frame)\n",
        "\n",
        "\n",
        "\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "final_video = \"final_video.mp4\"\n",
        "#.....text........function...................\n",
        "add_narration_to_video(output_file, final_video)\n",
        "\n",
        "#os.remove(\"narration.mp3\")\n",
        "print(f'Video saved as {final_video}')\n",
        "os.remove(output_file)"
      ],
      "metadata": {
        "id": "zbge1rxmvOU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}